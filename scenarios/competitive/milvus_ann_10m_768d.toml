# Competitive Baseline: Milvus Large-Scale ANN Benchmark (STRETCH GOAL)
#
# Replicates Milvus's published benchmark for large-scale ANN search
# Reference: https://milvus.io/docs/benchmark.md
#
# Benchmark details:
# - Dataset: 10M vectors, 768 dimensions (10x larger than Qdrant benchmark)
# - Target: 100% recall@10 accuracy (exact nearest neighbors)
# - Competitor P99: 708ms latency, 2,098 QPS throughput
# - Engram target: <100ms P99 (86% faster via GPU acceleration + HNSW)
#
# WARNING: This scenario requires ~16GB+ RAM for in-memory graph.
# Memory footprint: 10M * 768 * 4 bytes * 1.3 overhead = ~40GB theoretical
# Actual RSS should be ~10-15GB with compression.
#
# This is a STRETCH GOAL to demonstrate scalability. May require:
# - GPU acceleration enabled
# - Memory-mapped storage for cold tier
# - Incremental loading strategy

name = "Milvus ANN 10M Benchmark (Stretch Goal)"
description = "Large-scale ANN search workload matching Milvus benchmark (10M vectors, 768-dim)"

[duration]
total_seconds = 60

[arrival]
pattern = "constant"
rate = 500.0  # Start conservatively at 500 QPS (Milvus achieves 2,098 QPS)

[operations]
# Pure ANN search workload at scale
store_weight = 0.0
recall_weight = 0.0
embedding_search_weight = 1.0  # 100% vector similarity search
pattern_completion_weight = 0.0

[data]
num_nodes = 10_000_000  # 10M vectors for large-scale testing
embedding_dim = 768     # OpenAI ada-002 embedding dimension
memory_spaces = 1

# Clustered distribution with more clusters for 10M scale
embedding_distribution = { type = "clustered", num_clusters = 1000, std_dev = 0.15 }

[validation]
expected_p99_latency_ms = 100.0      # Aggressive target: 86% faster than Milvus 708ms
expected_throughput_ops_sec = 400.0   # Conservative throughput target
max_error_rate = 0.0                  # 100% recall target (exact search)

[chaos]
enabled = false
